{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Rules from a Language Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sophi\\Miniconda3\\envs\\MT\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import timeit\n",
    "from rule_extractor_original.Lenses_dataset.Horn import *\n",
    "from binarize_features import *\n",
    "from transformers import pipeline\n",
    "from helper_functions import *\n",
    "from scipy.special import comb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import variables and sizes with the binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fashion_designer': 0, 'nurse': 1, 'dancer': 2, 'priest': 3, 'footballer': 4, 'banker': 5, 'singer': 6, 'lawyer': 7, 'mathematician': 8, 'diplomat': 9}\n"
     ]
    }
   ],
   "source": [
    "country_file = 'data/country_list_continents.csv'\n",
    "occ_file = 'data/occupations_subset.csv'\n",
    "#occ_file = 'data/occupations_subset.csv'\n",
    "binarizer = Binarizer(country_file, 5, occ_file)\n",
    "print(binarizer.occupation_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fashion_designer' 'nurse' 'dancer' 'priest' 'footballer' 'banker'\n",
      " 'singer' 'lawyer' 'mathematician' 'diplomat']\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_csv('data/occupations_subset.csv').to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['roberta-base', 'roberta-large', 'bert-base-cased', 'bert-large-cased']\n",
    "# add one dimension for the gender variable (last variable in the vector)\n",
    "dim = sum(binarizer.lengths.values()) + 1\n",
    "V = define_variables(dim)\n",
    "language_model = models[1]\n",
    "#seed = 123 #reproducability\n",
    "epsilon = 0.3\n",
    "delta = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample size code taken from Lenses.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eq_sample_size(n_variables=dim, epsilon=epsilon, delta=delta):\n",
    "    return int((4/epsilon) * (log( log( Pow(2,comb(n_variables,n_variables/2)) ) )/delta) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create classified samples from the Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_sample(length, amount_of_true=1):\n",
    "    vec = np.zeros(length, dtype=np.int8)\n",
    "    idx = random.sample(range(length), k=amount_of_true)\n",
    "    for i in idx:\n",
    "        vec[i] = 1\n",
    "    return list(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mask> was born before 1892 in Central America and is a banker.\n",
      "([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 1, 0, 0)\n",
      "<mask> was born between 1956 and 1976 in Australia and is a banker.\n",
      "([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1], 1, 1, 1)\n",
      "<mask> was born between 1956 and 1976 in Americas and is a banker.\n",
      "([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 1, 0, 0)\n",
      "<mask> was born after 1976 in South America and is a mathematician.\n",
      "([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], 1, 1, 1)\n",
      "<mask> was born after 1976 in ? and is a lawyer.\n",
      "([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 1, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "#len(V) = num_variables\n",
    "attributes = ['birth', 'continent', 'occupation']\n",
    "#new tactic: \n",
    "#num_variables inherited by binarizer that has to be initialized\n",
    "def create_classified_sample_from_LM(lm : str, sample_size : int, binarizer : Binarizer, unmasker, verbose = False):\n",
    "    dataset = []\n",
    "    # create all the samples randomly by specific sampling strategy and classify them immediatley \n",
    "    # -> there is no time savings in using a batch of samples at once and therefore predictions can be done immediately\n",
    "    for i in range(sample_size):\n",
    "        vec = []\n",
    "        for att in attributes:\n",
    "            # get the appropriate vector for each attribute and tie them together in the end\n",
    "            vec = [*vec, *get_random_sample(binarizer.lengths[att])]\n",
    "        s = binarizer.sentence_from_binary(vec)\n",
    "        if verbose:\n",
    "            print(s)\n",
    "        classification = get_prediction(lm_inference(unmasker, s, model=lm), binary = True)\n",
    "        # get random gender as a fourth attribute (in the end of the vector)\n",
    "        gender = random.randint(0,1)\n",
    "        vec.append(gender)\n",
    "        # if the sampled gender is equal the classification (correctly classified) then we return 1 as 'is valid sentence' \n",
    "        # if sampled gender and classification don't match, the sample is not valid and we return 0 as a label\n",
    "        label = 1 if gender == classification else 0\n",
    "        if verbose:\n",
    "            print((vec,classification, gender, label))\n",
    "        dataset.append((vec,label))\n",
    "    return dataset\n",
    "dataset = create_classified_sample_from_LM(language_model, 5, binarizer, pipeline('fill-mask', model=language_model), verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define equivalence and membership queries for language model\n",
    "\n",
    "Adjust methods for equivalence and membership queries so that they fit with inputs and outputs for a language model. \n",
    "1. use modified `create_classified_sample_from_LM`\n",
    "2. replace prediction in MQ with prediction from language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_EQ(H, lm, unmasker, V, bad_nc, binarizer : Binarizer):\n",
    "    sample = create_classified_sample_from_LM(lm, get_eq_sample_size(), binarizer, unmasker)\n",
    "    h = true\n",
    "    if len(H):\n",
    "        h = set2theory(H)\n",
    "    for (a,l) in sample:\n",
    "        if l == 0 and evaluate(h,a,V) and a not in bad_nc:\n",
    "            return a\n",
    "        if l == 1 and not evaluate(h,a,V):\n",
    "            sample.remove((a,l))\n",
    "            return a\n",
    "    return True\n",
    "\n",
    "def custom_MQ(assignment, lm, unmasker, binarizer : Binarizer):\n",
    "    vec = assignment.copy()\n",
    "    gender = vec.pop()\n",
    "    s = binarizer.sentence_from_binary(vec)\n",
    "    classification = get_prediction(lm_inference(unmasker, s, model=lm), binary = True)\n",
    "    res  = ( True if classification == gender\n",
    "                else False)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify `extract_horn_with_queries` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_horn_with_queries_1(lm, V, iterations, binarizer, background, verbose = 0):\n",
    "    bad_pc = []\n",
    "    bad_ne =[]\n",
    "    unmasker = pipeline('fill-mask', model=lm)\n",
    "    mq = lambda a : custom_MQ(a, lm, unmasker, binarizer)\n",
    "    eq = lambda a : custom_EQ(a, lm, unmasker, V, bad_ne, binarizer)\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    h = learn(V, mq, eq, bad_ne, bad_pc, background = background, iterations=iterations, verbose = verbose)\n",
    "    stop = timeit.default_timer()\n",
    "    runtime = stop-start\n",
    "\n",
    "    runtime_per_iteration = runtime / iterations\n",
    "    return (h,runtime,runtime_per_iteration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiments \n",
    "\n",
    "Make a background that clarifies that some features can't appear at the same time to allow for the one-hot-encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[v0, v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13, v14, v15, v16, v17, v18, v19, v20, v21, v22, v23, v24, v25, v26, v27]\n",
      "{'birth': 5, 'continent': 12, 'occupation': 10}\n"
     ]
    }
   ],
   "source": [
    "print(V)\n",
    "print(binarizer.lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(~(V[0] & V[1])),\n",
      "(~(V[0] & V[2])),\n",
      "(~(V[0] & V[3])),\n",
      "(~(V[0] & V[4])),\n",
      "(~(V[1] & V[2])),\n",
      "(~(V[1] & V[3])),\n",
      "(~(V[1] & V[4])),\n",
      "(~(V[2] & V[3])),\n",
      "(~(V[2] & V[4])),\n",
      "(~(V[3] & V[4])),\n",
      "(~(V[5] & V[6])),\n",
      "(~(V[5] & V[7])),\n",
      "(~(V[5] & V[8])),\n",
      "(~(V[5] & V[9])),\n",
      "(~(V[5] & V[10])),\n",
      "(~(V[5] & V[11])),\n",
      "(~(V[5] & V[12])),\n",
      "(~(V[5] & V[13])),\n",
      "(~(V[5] & V[14])),\n",
      "(~(V[5] & V[15])),\n",
      "(~(V[5] & V[16])),\n",
      "(~(V[6] & V[7])),\n",
      "(~(V[6] & V[8])),\n",
      "(~(V[6] & V[9])),\n",
      "(~(V[6] & V[10])),\n",
      "(~(V[6] & V[11])),\n",
      "(~(V[6] & V[12])),\n",
      "(~(V[6] & V[13])),\n",
      "(~(V[6] & V[14])),\n",
      "(~(V[6] & V[15])),\n",
      "(~(V[6] & V[16])),\n",
      "(~(V[7] & V[8])),\n",
      "(~(V[7] & V[9])),\n",
      "(~(V[7] & V[10])),\n",
      "(~(V[7] & V[11])),\n",
      "(~(V[7] & V[12])),\n",
      "(~(V[7] & V[13])),\n",
      "(~(V[7] & V[14])),\n",
      "(~(V[7] & V[15])),\n",
      "(~(V[7] & V[16])),\n",
      "(~(V[8] & V[9])),\n",
      "(~(V[8] & V[10])),\n",
      "(~(V[8] & V[11])),\n",
      "(~(V[8] & V[12])),\n",
      "(~(V[8] & V[13])),\n",
      "(~(V[8] & V[14])),\n",
      "(~(V[8] & V[15])),\n",
      "(~(V[8] & V[16])),\n",
      "(~(V[9] & V[10])),\n",
      "(~(V[9] & V[11])),\n",
      "(~(V[9] & V[12])),\n",
      "(~(V[9] & V[13])),\n",
      "(~(V[9] & V[14])),\n",
      "(~(V[9] & V[15])),\n",
      "(~(V[9] & V[16])),\n",
      "(~(V[10] & V[11])),\n",
      "(~(V[10] & V[12])),\n",
      "(~(V[10] & V[13])),\n",
      "(~(V[10] & V[14])),\n",
      "(~(V[10] & V[15])),\n",
      "(~(V[10] & V[16])),\n",
      "(~(V[11] & V[12])),\n",
      "(~(V[11] & V[13])),\n",
      "(~(V[11] & V[14])),\n",
      "(~(V[11] & V[15])),\n",
      "(~(V[11] & V[16])),\n",
      "(~(V[12] & V[13])),\n",
      "(~(V[12] & V[14])),\n",
      "(~(V[12] & V[15])),\n",
      "(~(V[12] & V[16])),\n",
      "(~(V[13] & V[14])),\n",
      "(~(V[13] & V[15])),\n",
      "(~(V[13] & V[16])),\n",
      "(~(V[14] & V[15])),\n",
      "(~(V[14] & V[16])),\n",
      "(~(V[15] & V[16])),\n",
      "(~(V[17] & V[18])),\n",
      "(~(V[17] & V[19])),\n",
      "(~(V[17] & V[20])),\n",
      "(~(V[17] & V[21])),\n",
      "(~(V[17] & V[22])),\n",
      "(~(V[17] & V[23])),\n",
      "(~(V[17] & V[24])),\n",
      "(~(V[17] & V[25])),\n",
      "(~(V[17] & V[26])),\n",
      "(~(V[18] & V[19])),\n",
      "(~(V[18] & V[20])),\n",
      "(~(V[18] & V[21])),\n",
      "(~(V[18] & V[22])),\n",
      "(~(V[18] & V[23])),\n",
      "(~(V[18] & V[24])),\n",
      "(~(V[18] & V[25])),\n",
      "(~(V[18] & V[26])),\n",
      "(~(V[19] & V[20])),\n",
      "(~(V[19] & V[21])),\n",
      "(~(V[19] & V[22])),\n",
      "(~(V[19] & V[23])),\n",
      "(~(V[19] & V[24])),\n",
      "(~(V[19] & V[25])),\n",
      "(~(V[19] & V[26])),\n",
      "(~(V[20] & V[21])),\n",
      "(~(V[20] & V[22])),\n",
      "(~(V[20] & V[23])),\n",
      "(~(V[20] & V[24])),\n",
      "(~(V[20] & V[25])),\n",
      "(~(V[20] & V[26])),\n",
      "(~(V[21] & V[22])),\n",
      "(~(V[21] & V[23])),\n",
      "(~(V[21] & V[24])),\n",
      "(~(V[21] & V[25])),\n",
      "(~(V[21] & V[26])),\n",
      "(~(V[22] & V[23])),\n",
      "(~(V[22] & V[24])),\n",
      "(~(V[22] & V[25])),\n",
      "(~(V[22] & V[26])),\n",
      "(~(V[23] & V[24])),\n",
      "(~(V[23] & V[25])),\n",
      "(~(V[23] & V[26])),\n",
      "(~(V[24] & V[25])),\n",
      "(~(V[24] & V[26])),\n",
      "(~(V[25] & V[26])),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "background_string = \"{\"\n",
    "for idx, length in enumerate(binarizer.lengths.values()):\n",
    "    for i in range(length):\n",
    "        for j in range(i+1,length):\n",
    "            add = 0\n",
    "            if idx == 1:\n",
    "                add = 5\n",
    "            elif idx == 2:\n",
    "                add = 5 + 12\n",
    "            background_string = background_string + \"(~(V[\" + str(i+add) + \"] & V[\" + str(j+add) + \"])),\\n\"\n",
    "background_string = background_string + \"}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = {(~(V[0] & V[1])),\n",
    "(~(V[0] & V[2])),\n",
    "(~(V[0] & V[3])),\n",
    "(~(V[0] & V[4])),\n",
    "(~(V[1] & V[2])),\n",
    "(~(V[1] & V[3])),\n",
    "(~(V[1] & V[4])),\n",
    "(~(V[2] & V[3])),\n",
    "(~(V[2] & V[4])),\n",
    "(~(V[3] & V[4])),\n",
    "(~(V[5] & V[6])),\n",
    "(~(V[5] & V[7])),\n",
    "(~(V[5] & V[8])),\n",
    "(~(V[5] & V[9])),\n",
    "(~(V[5] & V[10])),\n",
    "(~(V[5] & V[11])),\n",
    "(~(V[5] & V[12])),\n",
    "(~(V[5] & V[13])),\n",
    "(~(V[5] & V[14])),\n",
    "(~(V[5] & V[15])),\n",
    "(~(V[5] & V[16])),\n",
    "(~(V[6] & V[7])),\n",
    "(~(V[6] & V[8])),\n",
    "(~(V[6] & V[9])),\n",
    "(~(V[6] & V[10])),\n",
    "(~(V[6] & V[11])),\n",
    "(~(V[6] & V[12])),\n",
    "(~(V[6] & V[13])),\n",
    "(~(V[6] & V[14])),\n",
    "(~(V[6] & V[15])),\n",
    "(~(V[6] & V[16])),\n",
    "(~(V[7] & V[8])),\n",
    "(~(V[7] & V[9])),\n",
    "(~(V[7] & V[10])),\n",
    "(~(V[7] & V[11])),\n",
    "(~(V[7] & V[12])),\n",
    "(~(V[7] & V[13])),\n",
    "(~(V[7] & V[14])),\n",
    "(~(V[7] & V[15])),\n",
    "(~(V[7] & V[16])),\n",
    "(~(V[8] & V[9])),\n",
    "(~(V[8] & V[10])),\n",
    "(~(V[8] & V[11])),\n",
    "(~(V[8] & V[12])),\n",
    "(~(V[8] & V[13])),\n",
    "(~(V[8] & V[14])),\n",
    "(~(V[8] & V[15])),\n",
    "(~(V[8] & V[16])),\n",
    "(~(V[9] & V[10])),\n",
    "(~(V[9] & V[11])),\n",
    "(~(V[9] & V[12])),\n",
    "(~(V[9] & V[13])),\n",
    "(~(V[9] & V[14])),\n",
    "(~(V[9] & V[15])),\n",
    "(~(V[9] & V[16])),\n",
    "(~(V[10] & V[11])),\n",
    "(~(V[10] & V[12])),\n",
    "(~(V[10] & V[13])),\n",
    "(~(V[10] & V[14])),\n",
    "(~(V[10] & V[15])),\n",
    "(~(V[10] & V[16])),\n",
    "(~(V[11] & V[12])),\n",
    "(~(V[11] & V[13])),\n",
    "(~(V[11] & V[14])),\n",
    "(~(V[11] & V[15])),\n",
    "(~(V[11] & V[16])),\n",
    "(~(V[12] & V[13])),\n",
    "(~(V[12] & V[14])),\n",
    "(~(V[12] & V[15])),\n",
    "(~(V[12] & V[16])),\n",
    "(~(V[13] & V[14])),\n",
    "(~(V[13] & V[15])),\n",
    "(~(V[13] & V[16])),\n",
    "(~(V[14] & V[15])),\n",
    "(~(V[14] & V[16])),\n",
    "(~(V[15] & V[16])),\n",
    "(~(V[17] & V[18])),\n",
    "(~(V[17] & V[19])),\n",
    "(~(V[17] & V[20])),\n",
    "(~(V[17] & V[21])),\n",
    "(~(V[17] & V[22])),\n",
    "(~(V[17] & V[23])),\n",
    "(~(V[17] & V[24])),\n",
    "(~(V[17] & V[25])),\n",
    "(~(V[17] & V[26])),\n",
    "(~(V[18] & V[19])),\n",
    "(~(V[18] & V[20])),\n",
    "(~(V[18] & V[21])),\n",
    "(~(V[18] & V[22])),\n",
    "(~(V[18] & V[23])),\n",
    "(~(V[18] & V[24])),\n",
    "(~(V[18] & V[25])),\n",
    "(~(V[18] & V[26])),\n",
    "(~(V[19] & V[20])),\n",
    "(~(V[19] & V[21])),\n",
    "(~(V[19] & V[22])),\n",
    "(~(V[19] & V[23])),\n",
    "(~(V[19] & V[24])),\n",
    "(~(V[19] & V[25])),\n",
    "(~(V[19] & V[26])),\n",
    "(~(V[20] & V[21])),\n",
    "(~(V[20] & V[22])),\n",
    "(~(V[20] & V[23])),\n",
    "(~(V[20] & V[24])),\n",
    "(~(V[20] & V[25])),\n",
    "(~(V[20] & V[26])),\n",
    "(~(V[21] & V[22])),\n",
    "(~(V[21] & V[23])),\n",
    "(~(V[21] & V[24])),\n",
    "(~(V[21] & V[25])),\n",
    "(~(V[21] & V[26])),\n",
    "(~(V[22] & V[23])),\n",
    "(~(V[22] & V[24])),\n",
    "(~(V[22] & V[25])),\n",
    "(~(V[22] & V[26])),\n",
    "(~(V[23] & V[24])),\n",
    "(~(V[23] & V[25])),\n",
    "(~(V[23] & V[26])),\n",
    "(~(V[24] & V[25])),\n",
    "(~(V[24] & V[26])),\n",
    "(~(V[25] & V[26]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/background.txt', 'wb') as f:\n",
    "    pickle.dump(background, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sophi\\Desktop\\MT_UiB\\extracting_rules.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sophi/Desktop/MT_UiB/extracting_rules.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m (h,runtime,runtime_per_iteration) \u001b[39m=\u001b[39m extract_horn_with_queries_1(language_model, V, \u001b[39m10\u001b[39;49m, binarizer, background, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sophi/Desktop/MT_UiB/extracting_rules.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(runtime,runtime_per_iteration)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sophi/Desktop/MT_UiB/extracting_rules.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(language_model \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_rules.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "\u001b[1;32mc:\\Users\\sophi\\Desktop\\MT_UiB\\extracting_rules.ipynb Cell 21\u001b[0m in \u001b[0;36mextract_horn_with_queries_1\u001b[1;34m(lm, V, iterations, binarizer, background, verbose)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sophi/Desktop/MT_UiB/extracting_rules.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m eq \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m a : custom_EQ(a, lm, unmasker, V, bad_ne, binarizer)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sophi/Desktop/MT_UiB/extracting_rules.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m start \u001b[39m=\u001b[39m timeit\u001b[39m.\u001b[39mdefault_timer()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sophi/Desktop/MT_UiB/extracting_rules.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m h \u001b[39m=\u001b[39m learn(V, mq, eq, bad_ne, bad_pc, background \u001b[39m=\u001b[39;49m background, iterations\u001b[39m=\u001b[39;49miterations, verbose \u001b[39m=\u001b[39;49m verbose)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sophi/Desktop/MT_UiB/extracting_rules.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m stop \u001b[39m=\u001b[39m timeit\u001b[39m.\u001b[39mdefault_timer()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sophi/Desktop/MT_UiB/extracting_rules.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m runtime \u001b[39m=\u001b[39m stop\u001b[39m-\u001b[39mstart\n",
      "File \u001b[1;32mc:\\Users\\sophi\\Desktop\\MT_UiB\\rule_extractor_original\\Lenses_dataset\\Horn.py:185\u001b[0m, in \u001b[0;36mlearn\u001b[1;34m(V, MQ, EQ, bad_nc, bad_pc, background, verbose, iterations, guard)\u001b[0m\n\u001b[0;32m    183\u001b[0m         H \u001b[39m=\u001b[39m get_hypothesis(S,V,bad_nc,background)\n\u001b[0;32m    184\u001b[0m         \u001b[39m#small optimisation. Refine hypo. with known positive counterexamples.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m         H \u001b[39m=\u001b[39m positive_check_and_prune(H,S,Pos,V,bad_nc)\n\u001b[0;32m    186\u001b[0m     iterations\u001b[39m-\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m    187\u001b[0m \u001b[39mreturn\u001b[39;00m H\n",
      "File \u001b[1;32mc:\\Users\\sophi\\Desktop\\MT_UiB\\rule_extractor_original\\Lenses_dataset\\Horn.py:108\u001b[0m, in \u001b[0;36mpositive_check_and_prune\u001b[1;34m(H, S, Pos, V, bad_nc)\u001b[0m\n\u001b[0;32m    105\u001b[0m             H\u001b[39m.\u001b[39mremove(clause)\n\u001b[0;32m    106\u001b[0m             \u001b[39m# identify_problematic_nc(H,S,bad_nc)\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m identify_problematic_nc(H,S,bad_nc,V)\n\u001b[0;32m    110\u001b[0m \u001b[39m# for clause in [c for c in H.copy() if type(c) == Implies]:\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39m#     for c2 in [c for c in H.copy() if  type(c) == Not]:\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39m#         if set(get_body(clause)).issubset(set(get_body(clause))):\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[39m#             H.discard(clause)\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39mreturn\u001b[39;00m H\n",
      "File \u001b[1;32mc:\\Users\\sophi\\Desktop\\MT_UiB\\rule_extractor_original\\Lenses_dataset\\Horn.py:125\u001b[0m, in \u001b[0;36midentify_problematic_nc\u001b[1;34m(H, S, bad_nc, V)\u001b[0m\n\u001b[0;32m    123\u001b[0m h\u001b[39m=\u001b[39mset2theory(H)\n\u001b[0;32m    124\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m [a \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m S \u001b[39mif\u001b[39;00m a \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m bad_nc]:\n\u001b[1;32m--> 125\u001b[0m     \u001b[39mif\u001b[39;00m (evaluate(h, a, V) \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    126\u001b[0m         bad_nc\u001b[39m.\u001b[39mappend(a)\n",
      "File \u001b[1;32mc:\\Users\\sophi\\Desktop\\MT_UiB\\rule_extractor_original\\Lenses_dataset\\Horn.py:38\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(formula, x, V)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m formula \u001b[39m==\u001b[39m false:\n\u001b[0;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m a \u001b[39m=\u001b[39m {V[i]: x[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(V))}\n\u001b[0;32m     39\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(V)):\n\u001b[0;32m     40\u001b[0m     a[V[i]] \u001b[39m=\u001b[39m (\u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m x[i] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     41\u001b[0m                     \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\sophi\\Desktop\\MT_UiB\\rule_extractor_original\\Lenses_dataset\\Horn.py:38\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m formula \u001b[39m==\u001b[39m false:\n\u001b[0;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m a \u001b[39m=\u001b[39m {V[i]: x[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(V))}\n\u001b[0;32m     39\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(V)):\n\u001b[0;32m     40\u001b[0m     a[V[i]] \u001b[39m=\u001b[39m (\u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m x[i] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     41\u001b[0m                     \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "(h,runtime,runtime_per_iteration) = extract_horn_with_queries_1(language_model, V, 10, binarizer, background, verbose=0)\n",
    "print(runtime,runtime_per_iteration)\n",
    "with open(language_model + '_rules.txt', 'wb') as f:\n",
    "    pickle.dump(h, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('MT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc686a98443b4652797a5cea7523f1dba0859ec3ace4f9579863ae6780390e66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
