{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a list of all countries in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_list = import_occupations(\"data/occupations_extracted.csv\")\n",
    "nids = []\n",
    "country_pairs = []\n",
    "for occupation in occ_list:\n",
    "        name = occupation[0]\n",
    "        df = pd.read_csv(f'data/csv_clean/{name}.csv')\n",
    "        for index, row in df.iterrows():\n",
    "            nationality = row['nationality']\n",
    "            nid = row['nationalityID']\n",
    "            if nid not in nids:\n",
    "                pair = [nid, nationality]\n",
    "                nids.append(nid)\n",
    "                country_pairs.append(pair)\n",
    "\n",
    "df = pd.DataFrame(country_pairs)\n",
    "df.to_csv('data/country_list.csv', index=False, header=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate all countries with their corresponding continent\n",
    "\n",
    "First, generate the list of continents associated with a country and add them all into one dataframe. Then associate those, that are not associated with a continent, with the unknown symbol '?'. Then find those, that have been added with multiple continents due to the hierarchical structure of data in wikidata and reasses by getting only their original countries continent (by adjusting their query)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple continents associated: \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/PhD/Horn_Envelope/Horn_Envelope/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 3",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m country_list \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/country_list_continents.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m country_list\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     22\u001b[0m         results \u001b[38;5;241m=\u001b[39m get_continent(row[\u001b[38;5;241m0\u001b[39m], original\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbindings\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m :\n",
      "File \u001b[0;32m~/Documents/PhD/Horn_Envelope/Horn_Envelope/.venv/lib/python3.13/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/Documents/PhD/Horn_Envelope/Horn_Envelope/.venv/lib/python3.13/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/Documents/PhD/Horn_Envelope/Horn_Envelope/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "country_list = pd.read_csv('data/country_list.csv', header=None)\n",
    "for index, row in country_list.iterrows():\n",
    "    cid = row[0]\n",
    "    if cid != '?':\n",
    "        results = get_continent(cid)\n",
    "        continents = [result['continent']['value'] for result in results['results']['bindings']]\n",
    "        country_list.at[index, 'continents'] = ','.join(continents) if continents else '?'\n",
    "\n",
    "        #for i, result in enumerate(results['results']['bindings']):\n",
    "        #    country_list.at[index,'continent'+str(i)] = result['continent']['value']\n",
    "country_list.to_csv('data/country_list_continents.csv', index=False, header=False)\n",
    "\n",
    "country_list = pd.read_csv('data/country_list_continents.csv', header=None)\n",
    "print(\"Multiple continents associated: \")\n",
    "for index, row in country_list.iterrows():\n",
    "    if not isinstance(row[2], str):\n",
    "        country_list.at[index, 2] = '?'\n",
    "country_list.to_csv('data/country_list_continents.csv', index=False, header=False)\n",
    "country_list = pd.read_csv('data/country_list_continents.csv', header=None)\n",
    "for index, row in country_list.iterrows():\n",
    "    if isinstance(row[3], str):\n",
    "        results = get_continent(row[0], original=True)\n",
    "        if len(results['results']['bindings']) == 1 :\n",
    "            country_list.at[index, 2] = results['results']['bindings'][0]['continent']['value']\n",
    "            for i in range(3,10):\n",
    "                country_list.at[index, i] = np.nan\n",
    "country_list.to_csv('data/country_list_continents.csv', index=False, header=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all countries that are still associated with more than one continent and manually fix them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q15180 Soviet Union\n",
      "Q804 Panama\n",
      "Q34266 Russian Empire\n",
      "Q664 New Zealand\n",
      "Q730 Suriname\n",
      "Q2002279 Portuguese Guinea\n",
      "Q702 Federated States of Micronesia\n",
      "Q139319 Russian Republic\n",
      "Q12544 Byzantine Empire\n",
      "Q12560 Ottoman Empire\n",
      "Q685 Solomon Islands\n",
      "Q23681 Northern Cyprus\n",
      "Q217196 Crown of Castile\n",
      "Q710 Kiribati\n",
      "Q695 Palau\n",
      "Q83891 Sasanian Empire\n",
      "Q160307 Fatimid Caliphate\n",
      "Q672 Tuvalu\n",
      "Q63135869 Ayyubid Sultanate\n",
      "Q282428 Mamluk Sultanate\n",
      "Q8575586 Umayyad Caliphate\n",
      "Q1275158 Elymais\n",
      "Q389688 Achaemenid Empire\n",
      "Q12490507 Rashidun Caliphate\n",
      "Q41137 Assyrian Empire\n",
      "Q180114 Ayyubid dynasty\n",
      "Q170468 United Arab Republic\n",
      "Q19083 Kingdom of Iberia\n",
      "Q80702 Spanish Empire\n",
      "Q8680 British Empire\n",
      "Q200464 Portuguese Empire\n",
      "Q210718 Asia\n",
      "Q186513 Hispania\n",
      "Q4304392 Russian State\n",
      "Q1051600 Duchy of Naples\n",
      "Q210551 Viceroyalty of the Río de la Plata\n",
      "Q10416611 Vandal Kingdom\n",
      "Q199688 Almohad Caliphate\n",
      "Q766543 Hispanic Monarchy\n"
     ]
    }
   ],
   "source": [
    "country_list = pd.read_csv('data/country_list_continents.csv', header=None)\n",
    "for index, row in country_list.iterrows():\n",
    "    if isinstance(row[3], str):\n",
    "        print(row[0], row[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automatic preprocessing is followed by manual manipulation of the country file to make it as clean as possible and associate all countries with their continent. This yields the final ``country_list_continents.csv`` file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make containers for age range\n",
    "1. Get all the birthyears from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_list = import_occupations(\"data/occupations_updated.csv\")\n",
    "amount_containers = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. clean the birthyears into being numbers (swapping BC with a negative value) and make a list of all years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "birthyears = []\n",
    "for occupation in occ_list:\n",
    "    id = occupation[1]\n",
    "    name = occupation[0]\n",
    "    occ_file = 'data/dataframes_cleaned/' + name + '.csv'\n",
    "    df = pd.read_csv(occ_file)\n",
    "    for index,row in df.iterrows():\n",
    "        birthyear = row['birth']\n",
    "        if isinstance(birthyear, str) and 'BC' in birthyear:\n",
    "            birthyears.append(-int(birthyear.split(' ')[0]))\n",
    "        elif birthyear == '?':\n",
    "            pass\n",
    "        else:\n",
    "            birthyears.append(int(birthyear))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Sort the birthyear list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "birthyears.sort()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Partition the list into the given amount of containers, so that years that are represented more ofte, gain a finer grained representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 1875\n",
      "1 : 1925\n",
      "2 : 1951\n",
      "3 : 1970\n"
     ]
    }
   ],
   "source": [
    "amount_in_container = int((len(birthyears) / amount_containers)+1)\n",
    "containers = []\n",
    "for i in range(amount_containers - 1):\n",
    "    c_value = birthyears[(i+1)*amount_in_container]\n",
    "    print(\"{i} : {value}\".format(i=i, value=c_value))\n",
    "    containers.append(c_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(containers).to_csv('data/age_containers' + str(amount_containers) + '.csv', header=None, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
